{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c895f294-28b9-47db-926f-95e76c6b383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run if you are developping/debugging\n",
    "# !pip install line_profiler\n",
    "%load_ext line_profiler\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667e8c1a-2782-44ca-8265-491d69a25930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from compgen2 import Gov, Matcher, GovTestData, Preprocessing\n",
    "from compgen2.const import FILENAME_VL, FILENAME_GOV_TEST_SET\n",
    "from compgen2.testdata import sample_test_set_from_gov, Synthetic, get_accuracy\n",
    "\n",
    "#random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d18a5d0-4e0e-42cc-8ad9-f41025bce6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root= Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe95d6-1241-4aef-a2cd-207f3022f01a",
   "metadata": {},
   "source": [
    "## Test sets\n",
    "We use 4 test sets:\n",
    "- different sample sets from the file \"deutsche-verlustlisten-1wk\"\n",
    "- different sample sets from the gov database \n",
    "- different sample sets from a synthetic data set that tries to mimic the errors found in the original \"verlustliste\"\n",
    "- manually collected correction suggestions from http://wiki-de.genealogy.net/Verlustlisten_Erster_Weltkrieg/Projekt/Ortsnamen\n",
    "\n",
    "All test sets change when preprocessing is applied.\n",
    "\n",
    "**Note**: We have a ground truth for all test setsbut the first one as the \"verlustliste\" is the actual problem we want to solve. So for the test set \"verlustliste\" we cannot calculate an accuracy score but we can compare who many items we were able to match. Assumption is that more matches are, in general, better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23618ed-61d7-47c1-a059-8d9815ef1838",
   "metadata": {},
   "source": [
    "## Test suite without Preprocessing -> Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1927d88-6f44-4f0b-96d2-259f338b2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91e1442-3538-428a-aa58-41a941a54aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = Gov(data_root)\n",
    "gov.load_data()\n",
    "gov.build_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a9bf91d-91cc-41bc-8a4c-d87807829c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set 1: VL\n",
    "assert data_root.joinpath(FILENAME_VL).exists()\n",
    "test_set_size = 200\n",
    "\n",
    "vl = pd.read_parquet(data_root / FILENAME_VL)  # location column has the test data, truth is unknown\n",
    "\n",
    "vl_test_sets = []\n",
    "vl_test_sets.append((\"vl test set with loc_count=1\", vl.query(\"loc_parts_count == 1\").sample(test_set_size)))\n",
    "vl_test_sets.append((\"vl test set with loc_count=2\", vl.query(\"loc_parts_count == 2\").sample(test_set_size)))\n",
    "vl_test_sets.append((\"vl test set with loc_count=3\", vl.query(\"loc_parts_count == 3\").sample(test_set_size)))\n",
    "vl_test_sets.append((\"vl test set containing '.'\", vl[vl.location.str.contains(\".\", regex=False)].sample(test_set_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f3586eb-079a-4a8c-8ec8-0eece7da313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set 2: Gov database\n",
    "test_set_size = 100\n",
    "\n",
    "gov_test_sets = []\n",
    "gov_test_sets.append((\"gov db test set with loc_count=1 and valid=1\", sample_test_set_from_gov(gov, size=test_set_size, num_parts=1, valid=1)))\n",
    "gov_test_sets.append((\"gov db test set with loc_count=1 and valid=0.7\", sample_test_set_from_gov(gov, size=test_set_size, num_parts=1, valid=0.7)))\n",
    "gov_test_sets.append((\"gov db test set with loc_count=2 and valid=1\", sample_test_set_from_gov(gov, size=test_set_size, num_parts=2, valid=1)))\n",
    "gov_test_sets.append((\"gov db test set with loc_count=2 and valid=0.7\", sample_test_set_from_gov(gov, size=test_set_size, num_parts=2, valid=0.7)))\n",
    "gov_test_sets.append((\"gov db test set with loc_count=3 and valid=1\", sample_test_set_from_gov(gov, size=test_set_size, num_parts=3, valid=1)))\n",
    "gov_test_sets.append((\"gov db test set with loc_count=3 and valid=0.7\", sample_test_set_from_gov(gov, size=test_set_size, num_parts=3, valid=0.7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f555c4-9ef8-43ae-a209-c31ef1d1bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set 3: Synthetic\n",
    "test_set_size = 100\n",
    "\n",
    "syn = Synthetic(gov)\n",
    "\n",
    "syn_test_sets = []\n",
    "syn_test_sets.append((\"syn test set with default probabilities\", syn.create_synthetic_test_set(test_set_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1766be-47c2-48e6-81ff-fe6c726c8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set 4: GovTestData\n",
    "assert data_root.joinpath(FILENAME_GOV_TEST_SET).exists()\n",
    "\n",
    "gtd = GovTestData(gov)\n",
    "gtd_test_sets = []\n",
    "gtd_test_sets.append((\"gov web test set\", gtd.get_test_set()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4733cd-b894-40b6-a880-31507c0eab87",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783a57ca-e8bc-4905-b3ae-eadd8efda818",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_row = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bef5ce-46f8-40d8-a9be-a6f5494d2c1e",
   "metadata": {},
   "source": [
    "Test Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73858549-b75a-4baf-892f-6e351703c817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running vl test set with loc_count=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████████████████████████████████████████████████████████████████| 200/200 [06:05<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 145 (72.5%).\n",
      "Counter({'No anchor at all': 55, 'KREISORSTADT': 49, 'gov only': 44, 'Phonetic': 40, 'Cost 2': 3, 'Cost 5': 3, 'Cost 1': 3, 'Cost 4': 2, 'Cost 3': 1})\n",
      "\n",
      "Running vl test set with loc_count=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████████████████████████████████████████████████████████████████| 200/200 [00:16<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 173 (86.5%).\n",
      "Counter({'gov only': 175, 'KREISORSTADT': 12, 'Phonetic': 10, 'Cost 3': 1, 'Cost 5': 1, 'Cost 2': 1})\n",
      "\n",
      "Running vl test set with loc_count=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████████████████████████████████████████████████████████████████| 200/200 [00:13<00:00, 15.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 82 (41.0%).\n",
      "Counter({'gov only': 186, 'KREISORSTADT': 12, 'Phonetic': 2})\n",
      "\n",
      "Running vl test set containing '.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████████████████████████████████████████████████████████████████| 200/200 [02:11<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 174 (87.0%).\n",
      "Counter({'gov only': 125, 'KREISORSTADT': 34, 'Phonetic': 20, 'No anchor at all': 18, 'Cost 5': 1, 'Cost 3': 1, 'Cost 4': 1})\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, test_set in vl_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches / test_set.location.nunique() * 100, 4)}%).\")\n",
    "    print(Counter(m.matching_method))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae111ca3-fd8b-4c4d-ab5b-dccfffd146ca",
   "metadata": {},
   "source": [
    "Test Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f66c9a65-a523-4ac1-9286-ef2a8ecefb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gov db test set with loc_count=1 and valid=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 46015.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 998 (99.8%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.998\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gov db test set with loc_count=1 and valid=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 49200.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 700 (70.0%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gov db test set with loc_count=2 and valid=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|██████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 813.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 993 (99.3%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.992\n",
      "\n",
      "Running gov db test set with loc_count=2 and valid=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 28703.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 698 (69.8%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gov db test set with loc_count=3 and valid=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [00:16<00:00, 60.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 994 (99.4%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.991\n",
      "\n",
      "Running gov db test set with loc_count=3 and valid=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|██████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 771.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 696 (69.6%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.696\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, test_set in gov_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches / test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a21252-6812-41c1-8c5c-84c48febc7a4",
   "metadata": {},
   "source": [
    "Test Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532070af-a6f7-48b4-bf06-3a8181b093c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running syn test set with default probabilities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations:  26%|███████████████████▉                                                        | 262/1000 [00:56<02:39,  4.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20821/163910244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_match_for_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"possible_matches\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total matches: {total_matches} ({round(total_matches /  test_set.location.nunique() * 100, 4)}%).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/gov/matcher.py\u001b[0m in \u001b[0;36mget_match_for_locations\u001b[0;34m(self, locations)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_match_for_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing locations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_parts_for_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_textual_id_for_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/gov/matcher.py\u001b[0m in \u001b[0;36mfind_parts_for_location\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mrelevant_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_relevant_names_from_part_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                     \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munmatched_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_COST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munmatched_part\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"candidates\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/gov/matcher.py\u001b[0m in \u001b[0;36mget_best_candidates\u001b[0;34m(self, relevant_names, name, max_cost)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cost\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mlC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocCorrection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/correction/loc_autocorrection.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, word, maxCost)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# recursively search each branch of the trie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             self._searchRecursive(\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/correction/loc_autocorrection.py\u001b[0m in \u001b[0;36m_searchRecursive\u001b[0;34m(self, node, letter, word, previousRow, results, maxCost)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 self._searchRecursive(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 )\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/correction/loc_autocorrection.py\u001b[0m in \u001b[0;36m_searchRecursive\u001b[0;34m(self, node, letter, word, previousRow, results, maxCost)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 self._searchRecursive(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 )\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/correction/loc_autocorrection.py\u001b[0m in \u001b[0;36m_searchRecursive\u001b[0;34m(self, node, letter, word, previousRow, results, maxCost)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 self._searchRecursive(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 )\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/correction/loc_autocorrection.py\u001b[0m in \u001b[0;36m_searchRecursive\u001b[0;34m(self, node, letter, word, previousRow, results, maxCost)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 self._searchRecursive(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 )\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/correction/loc_autocorrection.py\u001b[0m in \u001b[0;36m_searchRecursive\u001b[0;34m(self, node, letter, word, previousRow, results, maxCost)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 self._searchRecursive(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 )\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/correction/loc_autocorrection.py\u001b[0m in \u001b[0;36m_searchRecursive\u001b[0;34m(self, node, letter, word, previousRow, results, maxCost)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrentRow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 self._searchRecursive(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrentRow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxCost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 )\n",
      "\u001b[0;32m~/git_correlaid/compgen-ii-cgv/src/compgen2/correction/loc_autocorrection.py\u001b[0m in \u001b[0;36m_searchRecursive\u001b[0;34m(self, node, letter, word, previousRow, results, maxCost)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0minsertCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrentRow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mdeleteCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreviousRow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mreplaceCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreviousRow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for name, test_set in syn_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches /  test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32eab4-aeb8-431a-abae-8f6132e5957a",
   "metadata": {},
   "source": [
    "Test Set 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427460b0-f028-4575-96ba-7f6c58a27594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gov web test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████| 5641/5641 [06:43<00:00, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 5029 (90.1739%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.6462\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, test_set in gtd_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches /  test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea452bb-c0e4-4e10-a911-8cdb28240ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45162eb2-be3c-4de1-9b16-385e875f77e5",
   "metadata": {},
   "source": [
    "## Test suite with VL + Gov Preprocessing - replace corrections and characters, no substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f968849-a82d-4526-8336-c3e6fff453b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_row = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7586c39a-e044-4712-929f-400ae47b6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, test_set in vl_test_sets + gov_test_sets + syn_test_sets + gtd_test_sets:\n",
    "    test_set.location = Preprocessing.replace_corrections_vl(test_set.location)\n",
    "    test_set.location = Preprocessing.replace_characters_vl(test_set.location)\n",
    "    \n",
    "    if \"truth\" in test_set:\n",
    "        test_set.truth = Preprocessing.replace_corrections_vl(test_set.truth)\n",
    "        test_set.truth = Preprocessing.replace_characters_vl(test_set.truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15401dfb-b4cb-4636-800e-3be50241f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = Gov(data_root)\n",
    "gov.load_data()\n",
    "old_names = list(gov.ids_by_name.keys())\n",
    "new_names = Preprocessing.replace_characters_gov(pd.Series(old_names, dtype=str))\n",
    "\n",
    "for old_name, new_name in zip(old_names, new_names):\n",
    "    gov.ids_by_name[new_name] = gov.ids_by_name[old_name]\n",
    "    del gov.ids_by_name[old_name]\n",
    "    \n",
    "for id_ in gov.names_by_id:\n",
    "    names = gov.names_by_id[id_]\n",
    "    gov.names_by_id[id_] =  Preprocessing.replace_characters_gov(pd.Series(names, dtype=str))\n",
    "    \n",
    "gov.build_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b27b2b-29f9-4581-8990-e50644570364",
   "metadata": {},
   "source": [
    "Test Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6608817d-ec67-492d-9173-1a126a91f89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running vl test set with loc_count=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████| 1000/1000 [15:11<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 834 (83.4%).\n",
      "\n",
      "Running vl test set with loc_count=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████| 1000/1000 [00:47<00:00, 21.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 853 (85.3%).\n",
      "\n",
      "Running vl test set with loc_count=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████| 1000/1000 [00:46<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 500 (50.0%).\n",
      "\n",
      "Running vl test set containing '.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████| 1000/1000 [07:33<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 890 (89.0%).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, test_set in vl_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches / test_set.location.nunique() * 100, 4)}%).\")\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3079fc-e2bf-41ac-88a3-47c3a2f9080d",
   "metadata": {},
   "source": [
    "Test Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81e10179-ea3b-4bfc-9770-e642a6e4662e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gov db test set with loc_count=1 and valid=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 37038.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 998 (99.8%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.996\n",
      "\n",
      "Running gov db test set with loc_count=1 and valid=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 31243.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 698 (69.8%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.695\n",
      "\n",
      "Running gov db test set with loc_count=2 and valid=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|██████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5222.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 985 (98.5%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.982\n",
      "\n",
      "Running gov db test set with loc_count=2 and valid=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 31252.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 691 (69.1%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.685\n",
      "\n",
      "Running gov db test set with loc_count=3 and valid=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|███████████████████████████████████████████████████████| 1000/1000 [00:07<00:00, 128.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 974 (97.4%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.97\n",
      "\n",
      "Running gov db test set with loc_count=3 and valid=0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|███████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 676.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 687 (68.7%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, test_set in gov_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches / test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e1bc9-55f7-4164-9780-7dd859909e3c",
   "metadata": {},
   "source": [
    "Test Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "197e600c-c98a-478d-b11e-286bbbacf831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running syn test set with default probabilities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations: 100%|████████████████████████████████████████████████████████| 1000/1000 [02:06<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches: 971 (97.9818%).\n",
      "Accuracy (entries where all parts of truth are in possible matches): 0.806\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, test_set in syn_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches /  test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b65b544-5463-4eb8-a7bb-92260687fd9d",
   "metadata": {},
   "source": [
    "Test Set 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d5621-46b8-4f94-a6d3-8f0185328650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gov web test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing locations:  59%|█████████████████████████████████▏                      | 3349/5641 [03:58<02:53, 13.23it/s]"
     ]
    }
   ],
   "source": [
    "for name, test_set in gtd_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches /  test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc62b3-722b-4a04-b002-b7171bcaf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e700bf0-95c9-4dbe-9cb4-08977b35b37a",
   "metadata": {},
   "source": [
    "## Test suite with VL + Gov Preprocessing - replace corrections and characters + substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726c9f7-138f-4296-ac41-31ec6916baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_row = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ef802-aa1a-429b-9354-6ed92d850b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, test_set in vl_test_sets + gov_test_sets + syn_test_sets + gtd_test_sets:\n",
    "    test_set.location = Preprocessing.substitute_partial_words(test_set.location, data_root)\n",
    "    test_set.location = Preprocessing.substitute_delete_words(test_set.location, data_root)\n",
    "    test_set.location = Preprocessing.substitute_full_words(test_set.location, data_root)\n",
    "    \n",
    "    if \"truth\" in test_set:\n",
    "        test_set.truth = Preprocessing.substitute_partial_words(test_set.truth, data_root)\n",
    "        test_set.truth = Preprocessing.substitute_delete_words(test_set.truth, data_root)\n",
    "        test_set.truth = Preprocessing.substitute_full_words(test_set.truth, data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff29f2c-f1af-48e0-93a2-f3653fbefc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = Gov(data_root)\n",
    "gov.load_data()\n",
    "old_names = list(gov.ids_by_name.keys())\n",
    "new_names = Preprocessing.replace_characters_gov(pd.Series(old_names, dtype=str))\n",
    "new_names = Preprocessing.substitute_partial_words(pd.Series(new_names), data_root)\n",
    "new_names = Preprocessing.substitute_delete_words(pd.Series(new_names), data_root)\n",
    "new_names = Preprocessing.substitute_full_words(pd.Series(new_names), data_root)\n",
    "\n",
    "for old_name, new_name in zip(old_names, new_names):\n",
    "    gov.ids_by_name[new_name] = gov.ids_by_name[old_name]\n",
    "    del gov.ids_by_name[old_name]\n",
    "    \n",
    "for id_ in gov.names_by_id:\n",
    "    names = gov.names_by_id[id_]\n",
    "    new_names =  Preprocessing.replace_characters_gov(pd.Series(names, dtype=str))\n",
    "    new_names = Preprocessing.substitute_partial_words(pd.Series(new_names), data_root)\n",
    "    new_names = Preprocessing.substitute_delete_words(pd.Series(new_names), data_root)\n",
    "    new_names = Preprocessing.substitute_full_words(pd.Series(new_names), data_root)\n",
    "    \n",
    "gov.build_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d00bf-1159-4341-96d1-9fdf53923485",
   "metadata": {},
   "source": [
    "Test Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4bf5e-e175-4896-afa3-d9e42f04dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, test_set in vl_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches / test_set.location.nunique() * 100, 4)}%).\")\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f4da7-f327-4753-885e-bac4a2c688f6",
   "metadata": {},
   "source": [
    "Test Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d7499-c6f6-4857-b917-b2e8fcdc9b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, test_set in gov_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches / test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954a47a-27fc-4e38-87b4-1d93235cf744",
   "metadata": {},
   "source": [
    "Test Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd3759-2e7d-418d-b719-9ef98e0adc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, test_set in syn_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches /  test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20979682-2b08-43fe-aaf9-396ba1d98c86",
   "metadata": {},
   "source": [
    "Test Set 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485823f3-a95d-427e-afa4-8366e6671306",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, test_set in gtd_test_sets:\n",
    "    m = Matcher(gov)\n",
    "    print(\"Running\", name)\n",
    "    m.get_match_for_locations(test_set.location)\n",
    "    total_matches = len([match for match in m.results.values() if match.get(\"possible_matches\")])\n",
    "    print(f\"Total matches: {total_matches} ({round(total_matches /  test_set.location.nunique() * 100, 4)}%).\")\n",
    "    \n",
    "    accuracy = get_accuracy(m.results, test_set)\n",
    "    print(\"Accuracy (entries where all parts of truth are in possible matches):\", round(accuracy, 4))\n",
    "    print()\n",
    "    \n",
    "    result_row.append(total_matches / test_set.location.nunique())\n",
    "    result_row.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4f656-6094-414b-89d9-53f0214b7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34539474-d6fb-464c-8102-f192fa95b1a2",
   "metadata": {},
   "source": [
    "## Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1dad1-c716-4813-ae9c-883755875f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for name, test_set in vl_test_sets + gov_test_sets + syn_test_sets + gtd_test_sets:\n",
    "    for metric in ['total matches', 'accuracy']:\n",
    "        if name.startswith(\"vl\") and metric == 'accuracy':\n",
    "            continue\n",
    "            \n",
    "        names.append(name + ' ' + metric)\n",
    "        \n",
    "final_results = pd.DataFrame(final_results, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f982a-1165-4a95-b7a7-e9ce54b39634",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results[\"test set\"] = [\"Baseline\", \"Preprocessing VL (corrections + characters)\",  \"Preprocessing VL + Gov (corrections + characters)\",  \"Preprocessing VL + Gov (corrections + characters + substitution)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd851b93-2525-4ab3-8a5c-3eb68ac65a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = final_results.set_index(\"test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b2a0b-d635-4799-b0ec-e67b29e8eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv(\"final_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e034086f-240e-4cd2-af0a-13a3127a71f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
